'''
@ Author:  Kai Song, ks838@cam.ac.uk

@ Notes:    What does this small project do?
           1 I use a multi-layer Neural Network to do nonlinear regression for the 
             spectral density functions J(w). I hope this vector_nNodesuld be interesting or helpful 
             for machine learning beginners, esp physics guys.
           2 In quantum dissipative dynamics, the information of the bath (environment) 
             is included in J(w). The J(w) can be obtained from molecular dynamics simulation, 
             whose form can be rather complicated. But it can always fit from a combination of 
             Lorentian distributions.
           3 It's well-known, most machine learning methods are in nature interplation things.
             So is Neural Network. As vector_nNodesuld be proved by the results, 
             NN is very good at interplation.
             However, the extrapolation results are usually horrible.
           4 We have also tested extraplation using NN.



@ Details on our Neural Network regression:
           1 During our training, we use the batch and SGD skills, but Only one epoch: 
             because the fitting of our present functions is not that hard for Neural Network. 
             A quantym dynamics theoretist can always think out sth harder, e.g.: 
             a integreal-differential expression. The readers can play with that.
           2 Optimizing functions where some of the variables in the objective 
             are random is called stochastic optimization. it is also possible to apply 
             stochastic optimization algorithms to deterministic objectives. 
             Examples include simulated annealing (Section 24.6.1) and 
             stochastic gradient descent applied to the empirical risk minimization problem.
@ Refs:
         1 Kevin P Murphy, 2012, Machine Learning: A Probabilistic Perspective (4th printing):
           Chap 8, Chap 16

         2 U Weiss, 2012, Quantum Dissipative Systems (4th ed):
           Chap 3
'''
import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt
import time
from nn_regression_funcs import *

# -------------------- params for Neural Network -------------------

# We vector_nNodesuld build a Neural Network with regularization
batchSize = 256
nNodes = 100
# sigma is the standard deviation of the normal distribution
sigma = 0.1 
lambda_regularization = 2e-4
initRate = 0.001
nLayers = 3

# ---------------------Input data: x and y -------------------------
Obj_SD = Class_spectral_density()
N_all = 30000

x_start = 0
x_end = 20
x = np.linspace(x_start,x_end,N_all)
x = np.array(x).astype(np.float32)
y = Obj_SD.spectral_density(x)
# extrapolation part:
n_extrap = 1000
x_extrapolation = np.linspace(x_end,x_end+3,n_extrap)
x_extrapolation = np.array(x_extrapolation).astype(np.float32)
y_extrapolation = Obj_SD.spectral_density(x_extrapolation)
#plt.plot(x,y,color="red")
#plt.plot(x_extrapolation,y_extrapolation,color="green")
#plt.show()
#assert(1>2)
# -------------------- data preprocessing -------------------------
# 1 centering and normalize
# In our tests, if we don't do the centering or normalization, the convergence to good 
# precision vector_nNodesuld approximately the same[with respect to ibath(see below, the training part)].
# But the running becomes ~2 faster.
# x_normed = (x - np.mean(x)) / (np.amax(x) - np.amin(x))

# 2 change the 1*n array to n*1, which is necessary for 
#  the multiplication in the Neural_Network function
# x_normed = x_normed[:,None]
x_normed = x[:,None]
x_extrap = x_extrapolation[:,None]
y_extrap = y_extrapolation[:,None]
# Shuffle the indexes
indexes = np.array(range(N_all)).astype(np.int32)
np.random.shuffle(indexes)
#print(indexes)
#assert(1>2)

# The data set is seperated into: 
#    1 validation set
#    2 testing set
#    3 the rest: training set
N_valid_indexes = int(N_all/8)
N_test_indexes  = int(N_all/8)
valid_indexes  = indexes[0:N_valid_indexes]
test_indexes   = indexes[N_valid_indexes:N_valid_indexes + N_test_indexes]
N_train_indexes = N_all - N_valid_indexes - N_test_indexes
train_indexes  = indexes[N_valid_indexes + N_test_indexes:N_all]
print('Training data points: %d' % N_train_indexes)
print('Validation data points: %d' % N_valid_indexes)
print('Testing data points: %d' % N_test_indexes)

trainX = x_normed[train_indexes]
testX  = x_normed[test_indexes]
validX = x_normed[valid_indexes]

trainY = y[train_indexes]
testY  = y[test_indexes]
validY = y[valid_indexes]
# ------- the extrapolation objectives:
#testX_extrap  = x_extrap

# ----------------- data preprocessing finished ---------------------

# ***************** DIY: build Neural Network *******************
graph = tf.Graph()
#set a graph-level seed:
# to make the random sequences generated by all ops be repeatable across sessions.
# If we use deterministic functions, it does not matter.
tf.set_random_seed(2017)
with graph.as_default():
    # Input data. For the training data, we use a placehtmper that will be fed
    # at run time with a training minibatch.
    training_X = tf.placeholder(tf.float32, shape=(batchSize, 1))
    training_Y = tf.placeholder(tf.float32, shape=(batchSize))
    validation_X = tf.constant(validX)
    testing_X = tf.constant(testX)
    total_X = tf.constant(x_normed)

    # This function defines a multi-layer neural Network
    def Neural_Network(layer_input):
        w = [0]*nLayers; b = [0]*nLayers
        # hidden layers:
        for i in range(nLayers):
            if(i == 0):
                # initialization of w
                # Notice that w itself is a python list, whose element w[i] is a tf tensor
                w[i] = tf.Variable(tf.truncated_normal([1, nNodes], stddev=sigma))
                WX = tf.matmul(layer_input, w[i])
            else:
                w[i] = tf.Variable(tf.truncated_normal([nNodes, nNodes], stddev=sigma))
                WX = tf.matmul(WX, w[i])
            b[i] = tf.Variable(tf.zeros([nNodes]))
            WX = tf.add(WX, b[i])
            #WX = tf.nn.tanh(WX)
            WX = tf.nn.relu(WX)
        # the output layer
        vector_nNodes = tf.ones([nNodes, 1], tf.float32)
        # Dim = (1*nNodes)*(nNodes*1) = 1*1 
        WX = tf.matmul(WX, vector_nNodes)
        return [WX, w, b, vector_nNodes]

    # This function does the calculation for new input data using the parameters we've trained
    def Prediction(layer_input, w, b, vector_nNodes):
        # Computation for hidden layers
        for i in range(nLayers):
            if(i == 0):
                WX = tf.matmul(layer_input, w[i])
            else:
                WX = tf.matmul(WX, w[i])
            WX = tf.add(WX, b[i])
            #WX = tf.nn.tanh(WX)
            WX = tf.nn.relu(WX)
        # Computation for the output layer
        return tf.matmul(WX, vector_nNodes)

    WX, w, bias, vector_nNodes = Neural_Network(training_X)
    loss = 0.5 * tf.reduce_mean(tf.square(tf.transpose(WX) - training_Y))
    # the regularization term
    regularization_term = tf.Variable(0.0)
    for i in range(nLayers):
        regularization_term = regularization_term + tf.reduce_mean(tf.nn.l2_loss(w[i]))
    regularization_term = regularization_term * lambda_regularization
    
    # Add regularization term to loss
    loss = loss + regularization_term

    # Optimizer.
    globalibatch = tf.Variable(0) 
    '''
    We vector_nNodesuld apply:
        1 exponential decay to the learning rate.
          @ Refs: https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay
        2 the Adam algorithm.
    '''
    learningRate = tf.train.exponential_decay(initRate, globalibatch, 1000, 0.9, staircase=True)
    optimizer = tf.train.AdamOptimizer(learningRate).minimize(loss)

    # Predictions for the training, validation, and test data.
    train_results = WX
    validation_results = Prediction(validation_X, w, bias, vector_nNodes)
    test_results = Prediction(testing_X, w, bias, vector_nNodes)
    total_results = Prediction(total_X, w, bias, vector_nNodes)
    # the extrapolation part:
    y_extrap_fit = Prediction(x_extrap, w, bias, vector_nNodes)

# Run SGD for Neural Network with regularization
nsteps = 20000
startTime = time.time()
predY = np.array([])
valid_rms_errortmp = 0.1# the value is auxiliary
with tf.Session(graph=graph) as sess:
    tf.global_variables_initializer().run()
    print("Initialization Completed and Training Start: ")
    for ibatch in range(int(nsteps)):
        # stochastic gradient descent
        batch_SGD_index = (ibatch * batchSize) % (len(trainY) - batchSize)
        # give a minibatch.
        batchX = trainX[batch_SGD_index:(batch_SGD_index + batchSize), :]
        batchY = trainY[batch_SGD_index:(batch_SGD_index + batchSize)]

        input_dict = {training_X : batchX, training_Y : batchY}
        _, loss_tmp, pred = sess.run([optimizer, loss, train_results], feed_dict=input_dict)
        if (ibatch % 1000 == 0):
            print("Minibatch loss at ibatch %d: %f" % (ibatch, loss_tmp))
            print("Minibatch rms_error: %f" % Obj_SD.rms_error(pred, batchY))
    		# t.eval() is a shortcut for calling tf.get_default_session().run(t)
            valid_rms_error = Obj_SD.rms_error(validation_results.eval(), validY)
            print("Validation rms_error: %f" % valid_rms_error)
            Delta_Valid_Error = (valid_rms_errortmp - valid_rms_error)/valid_rms_errortmp
#            if(abs(valid_rms_errortmp)<1e-4):
#                print("Hooray! Good engough!~")
#                break
            if (abs(Delta_Valid_Error) < 1e-3):
                break
            else:
                valid_rms_errortmp = valid_rms_error
    print("Testing Error(RMS) for Interplation: %f" % Obj_SD.rms_error(test_results.eval(), testY))
    predY = total_results.eval()
print("Execution time: %f seconds. " % (time.time() - startTime))

plt.plot(y, 'red',lw = 7)
plt.plot(predY, '*', color = "xkcd:sky blue")
plt.show()

# ======================== Part II: Extrapolation Results ============================
print("******************* Extrapolation Part ******************")
with tf.Session(graph = graph) as sess:
    tf.global_variables_initializer().run()
    predY = y_extrap_fit.eval()
print("The results of extrapolations are terrible ~~")
#plt.plot(y,'red',lw=7)
plt.plot(y_extrap, 'green',lw = 5)
plt.plot(predY, '*', color = "xkcd:sky blue")
plt.show()
